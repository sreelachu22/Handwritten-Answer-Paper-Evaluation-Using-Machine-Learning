{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"colab":{"name":"Correction Final 1.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"HdYe8Tl5We1e"},"source":["# Paper Correction\n","This module is to create a model from a key answer and use it to score other answers"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k_Tet5o5BHnR","executionInfo":{"status":"ok","timestamp":1622187643578,"user_tz":-330,"elapsed":263926,"user":{"displayName":"Answer Evaluation","photoUrl":"","userId":"02627252920565144362"}},"outputId":"bda0dee6-20d6-4850-a506-8f2fb9f606ef"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zi-szjoHXt3D","executionInfo":{"status":"ok","timestamp":1622187968809,"user_tz":-330,"elapsed":105554,"user":{"displayName":"Answer Evaluation","photoUrl":"","userId":"02627252920565144362"}},"outputId":"eb87f9bf-4c08-4143-d125-e750ad128ba2"},"source":["!pip install -U spacy\n","!python -m spacy download en_core_web_lg\n","!python -m spacy download en_core_web_sm"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting spacy\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/d8/0361bbaf7a1ff56b44dca04dace54c82d63dad7475b7d25ea1baefafafb2/spacy-3.0.6-cp37-cp37m-manylinux2014_x86_64.whl (12.8MB)\n","\u001b[K     |████████████████████████████████| 12.8MB 314kB/s \n","\u001b[?25hCollecting typer<0.4.0,>=0.3.0\n","  Downloading https://files.pythonhosted.org/packages/90/34/d138832f6945432c638f32137e6c79a3b682f06a63c488dcfaca6b166c64/typer-0.3.2-py3-none-any.whl\n","Collecting pathy>=0.3.5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/87/5991d87be8ed60beb172b4062dbafef18b32fa559635a8e2b633c2974f85/pathy-0.5.2-py3-none-any.whl (42kB)\n","\u001b[K     |████████████████████████████████| 51kB 7.1MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (20.9)\n","Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.5)\n","Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (56.1.0)\n","Requirement already satisfied, skipping upgrade: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy) (3.7.4.3)\n","Requirement already satisfied, skipping upgrade: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n","Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n","Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.41.1)\n","Collecting srsly<3.0.0,>=2.4.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/84/dfdfc9f6f04f6b88207d96d9520b911e5fec0c67ff47a0dea31ab5429a1e/srsly-2.4.1-cp37-cp37m-manylinux2014_x86_64.whl (456kB)\n","\u001b[K     |████████████████████████████████| 460kB 35.2MB/s \n","\u001b[?25hCollecting pydantic<1.8.0,>=1.7.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/fa/d43f31874e1f2a9633e4c025be310f2ce7a8350017579e9e837a62630a7e/pydantic-1.7.4-cp37-cp37m-manylinux2014_x86_64.whl (9.1MB)\n","\u001b[K     |████████████████████████████████| 9.1MB 17.4MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n","Collecting thinc<8.1.0,>=8.0.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/87/decceba68a0c6ca356ddcb6aea8b2500e71d9bc187f148aae19b747b7d3c/thinc-8.0.3-cp37-cp37m-manylinux2014_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 33.0MB/s \n","\u001b[?25hCollecting spacy-legacy<3.1.0,>=3.0.4\n","  Downloading https://files.pythonhosted.org/packages/8d/67/d4002a18e26bf29b17ab563ddb55232b445ab6a02f97bf17d1345ff34d3f/spacy_legacy-3.0.5-py2.py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n","Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n","Collecting catalogue<2.1.0,>=2.0.3\n","  Downloading https://files.pythonhosted.org/packages/9c/10/dbc1203a4b1367c7b02fddf08cb2981d9aa3e688d398f587cea0ab9e3bec/catalogue-2.0.4-py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n","Requirement already satisfied, skipping upgrade: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n","Requirement already satisfied, skipping upgrade: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n","Collecting smart-open<4.0.0,>=2.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/9a/ba2d5f67f25e8d5bbf2fcec7a99b1e38428e83cb715f64dd179ca43a11bb/smart_open-3.0.0.tar.gz (113kB)\n","\u001b[K     |████████████████████████████████| 122kB 32.5MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (2.4.7)\n","Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n","Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n","Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n","Requirement already satisfied, skipping upgrade: zipp>=0.5; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.3->spacy) (3.4.1)\n","Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n","Building wheels for collected packages: smart-open\n","  Building wheel for smart-open (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for smart-open: filename=smart_open-3.0.0-cp37-none-any.whl size=107098 sha256=ffcad7ea1b2372baaeb209556dbf9b8de0243e105a982e8d84ce35eafd83e3ae\n","  Stored in directory: /root/.cache/pip/wheels/18/88/7c/f06dabd5e9cabe02d2269167bcacbbf9b47d0c0ff7d6ebcb78\n","Successfully built smart-open\n","Installing collected packages: typer, smart-open, pathy, catalogue, srsly, pydantic, thinc, spacy-legacy, spacy\n","  Found existing installation: smart-open 5.0.0\n","    Uninstalling smart-open-5.0.0:\n","      Successfully uninstalled smart-open-5.0.0\n","  Found existing installation: catalogue 1.0.0\n","    Uninstalling catalogue-1.0.0:\n","      Successfully uninstalled catalogue-1.0.0\n","  Found existing installation: srsly 1.0.5\n","    Uninstalling srsly-1.0.5:\n","      Successfully uninstalled srsly-1.0.5\n","  Found existing installation: thinc 7.4.0\n","    Uninstalling thinc-7.4.0:\n","      Successfully uninstalled thinc-7.4.0\n","  Found existing installation: spacy 2.2.4\n","    Uninstalling spacy-2.2.4:\n","      Successfully uninstalled spacy-2.2.4\n","Successfully installed catalogue-2.0.4 pathy-0.5.2 pydantic-1.7.4 smart-open-3.0.0 spacy-3.0.6 spacy-legacy-3.0.5 srsly-2.4.1 thinc-8.0.3 typer-0.3.2\n","2021-05-28 07:44:45.520674: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n","Collecting en-core-web-lg==3.0.0\n","\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.0.0/en_core_web_lg-3.0.0-py3-none-any.whl (778.8MB)\n","\u001b[K     |████████████████████████████████| 778.8MB 20kB/s \n","\u001b[?25hRequirement already satisfied: spacy<3.1.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-lg==3.0.0) (3.0.6)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (2.11.3)\n","Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (3.7.4.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (56.1.0)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (2.23.0)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (2.4.1)\n","Requirement already satisfied: thinc<8.1.0,>=8.0.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (8.0.3)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (4.41.1)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (0.4.1)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (1.0.5)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (2.0.5)\n","Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (0.8.2)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (3.0.5)\n","Requirement already satisfied: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (0.3.2)\n","Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (1.7.4)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (1.19.5)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (2.0.4)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (0.5.2)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (3.0.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (20.9)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (2.0.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (2.10)\n","Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (7.1.2)\n","Requirement already satisfied: zipp>=0.5; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.3->spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (3.4.1)\n","Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (3.0.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (2.4.7)\n","Installing collected packages: en-core-web-lg\n","Successfully installed en-core-web-lg-3.0.0\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_lg')\n","2021-05-28 07:46:00.457685: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n","Collecting en-core-web-sm==3.0.0\n","\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0-py3-none-any.whl (13.7MB)\n","\u001b[K     |████████████████████████████████| 13.7MB 7.8MB/s \n","\u001b[?25hRequirement already satisfied: spacy<3.1.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-sm==3.0.0) (3.0.6)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.0.5)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.1)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.19.5)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.5)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.23.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.11.3)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.5)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.5.2)\n","Requirement already satisfied: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.3.2)\n","Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.7.4.3)\n","Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.8.2)\n","Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.7.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (56.1.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (20.9)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.5)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (4.41.1)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.4.1)\n","Requirement already satisfied: thinc<8.1.0,>=8.0.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (8.0.3)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.4)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.1)\n","Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.0)\n","Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (7.1.2)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.7)\n","Requirement already satisfied: zipp>=0.5; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.3->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.4.1)\n","Installing collected packages: en-core-web-sm\n","  Found existing installation: en-core-web-sm 2.2.5\n","    Uninstalling en-core-web-sm-2.2.5:\n","      Successfully uninstalled en-core-web-sm-2.2.5\n","Successfully installed en-core-web-sm-3.0.0\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_sm')\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3lYFhJBtYlCi","executionInfo":{"status":"ok","timestamp":1622188048124,"user_tz":-330,"elapsed":7177,"user":{"displayName":"Answer Evaluation","photoUrl":"","userId":"02627252920565144362"}},"outputId":"e4501510-9c2e-4776-e7df-bcf26bcae6cc"},"source":["pip install rake-nltk"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting rake-nltk\n","  Downloading https://files.pythonhosted.org/packages/8e/c4/b4ff57e541ac5624ad4b20b89c2bafd4e98f29fd83139f3a81858bdb3815/rake_nltk-1.0.4.tar.gz\n","Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from rake-nltk) (3.2.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->rake-nltk) (1.15.0)\n","Building wheels for collected packages: rake-nltk\n","  Building wheel for rake-nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for rake-nltk: filename=rake_nltk-1.0.4-py2.py3-none-any.whl size=7819 sha256=47f24009171fd21d62f42138d302d8dc10cbf6a375ef6e6ab86cca2ea407ed8d\n","  Stored in directory: /root/.cache/pip/wheels/ef/92/fc/271b3709e71a96ffe934b27818946b795ac6b9b8ff8682483f\n","Successfully built rake-nltk\n","Installing collected packages: rake-nltk\n","Successfully installed rake-nltk-1.0.4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4WtRUWhHY2GY","executionInfo":{"status":"ok","timestamp":1622188055515,"user_tz":-330,"elapsed":4965,"user":{"displayName":"Answer Evaluation","photoUrl":"","userId":"02627252920565144362"}},"outputId":"b0f84bd5-d8be-4ae3-d2b4-6e9a7074c7f4"},"source":["pip install pytextrank"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting pytextrank\n","  Downloading https://files.pythonhosted.org/packages/dc/bc/df8b57f1c28e2b66859b7428520115723a7c49ce6e4d1a224307dbe079dd/pytextrank-3.1.1-py3-none-any.whl\n","Collecting icecream>=2.1\n","  Downloading https://files.pythonhosted.org/packages/31/cc/5454531fe9ae123720b496fdea806e282843d6e75e5718a5e8b1d8e5c47f/icecream-2.1.0-py2.py3-none-any.whl\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from pytextrank) (2.5.1)\n","Requirement already satisfied: spacy>=3.0 in /usr/local/lib/python3.7/dist-packages (from pytextrank) (3.0.6)\n","Collecting graphviz>=0.13\n","  Downloading https://files.pythonhosted.org/packages/86/86/89ba50ba65928001d3161f23bfa03945ed18ea13a1d1d44a772ff1fa4e7a/graphviz-0.16-py2.py3-none-any.whl\n","Collecting asttokens>=2.0.1\n","  Downloading https://files.pythonhosted.org/packages/16/d5/b0ad240c22bba2f4591693b0ca43aae94fbd77fb1e2b107d54fff1462b6f/asttokens-2.0.5-py2.py3-none-any.whl\n","Collecting executing>=0.3.1\n","  Downloading https://files.pythonhosted.org/packages/e1/a6/07d28b53b1fab42985cba6b704d685a60a2e3a5efce4cfaaad42a4494bd8/executing-0.6.0-py2.py3-none-any.whl\n","Collecting colorama>=0.3.9\n","  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n","Requirement already satisfied: pygments>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from icecream>=2.1->pytextrank) (2.6.1)\n","Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->pytextrank) (4.4.2)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0->pytextrank) (3.0.5)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0->pytextrank) (2.0.4)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.4 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0->pytextrank) (3.0.5)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0->pytextrank) (0.4.1)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0->pytextrank) (2.0.5)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0->pytextrank) (1.19.5)\n","Requirement already satisfied: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0->pytextrank) (0.3.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0->pytextrank) (56.1.0)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0->pytextrank) (0.5.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0->pytextrank) (20.9)\n","Requirement already satisfied: thinc<8.1.0,>=8.0.3 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0->pytextrank) (8.0.3)\n","Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0->pytextrank) (3.7.4.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0->pytextrank) (2.11.3)\n","Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0->pytextrank) (1.7.4)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0->pytextrank) (2.23.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0->pytextrank) (4.41.1)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0->pytextrank) (1.0.5)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0->pytextrank) (2.4.1)\n","Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0->pytextrank) (0.8.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from asttokens>=2.0.1->icecream>=2.1->pytextrank) (1.15.0)\n","Requirement already satisfied: zipp>=0.5; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.3->spacy>=3.0->pytextrank) (3.4.1)\n","Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy>=3.0->pytextrank) (7.1.2)\n","Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy>=3.0->pytextrank) (3.0.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy>=3.0->pytextrank) (2.4.7)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy>=3.0->pytextrank) (2.0.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0->pytextrank) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0->pytextrank) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0->pytextrank) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0->pytextrank) (2.10)\n","Installing collected packages: asttokens, executing, colorama, icecream, graphviz, pytextrank\n","  Found existing installation: graphviz 0.10.1\n","    Uninstalling graphviz-0.10.1:\n","      Successfully uninstalled graphviz-0.10.1\n","Successfully installed asttokens-2.0.5 colorama-0.4.4 executing-0.6.0 graphviz-0.16 icecream-2.1.0 pytextrank-3.1.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CaXAHyBTWe1n","executionInfo":{"status":"ok","timestamp":1622188067664,"user_tz":-330,"elapsed":4833,"user":{"displayName":"Answer Evaluation","photoUrl":"","userId":"02627252920565144362"}}},"source":["import string\n","import re\n","from math import *\n","import time\n","import spacy\n","import en_core_web_lg\n","from rake_nltk import Rake\n","import pytextrank\n","from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n","from gensim.models import KeyedVectors\n","import numpy as np\n","from sklearn.metrics.pairwise import cosine_similarity\n","from nltk.tokenize import word_tokenize, sent_tokenize\n","from nltk.util import ngrams\n","from nltk.stem import WordNetLemmatizer\n","from nltk.corpus import stopwords\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","nlp = spacy.load('en_core_web_sm')"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aB2IKh_oWe1s"},"source":["# Initialising preprocessing metrics"]},{"cell_type":"code","metadata":{"id":"QKqWV7eyWe1t","executionInfo":{"status":"ok","timestamp":1622188266999,"user_tz":-330,"elapsed":137723,"user":{"displayName":"Answer Evaluation","photoUrl":"","userId":"02627252920565144362"}}},"source":["lemmatizer = WordNetLemmatizer()\n","stopw = set(stopwords.words('english'))\n","remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)\n","sp = en_core_web_lg.load()\n","r = Rake()\n","sp.add_pipe(\"textrank\")\n","model1 = KeyedVectors.load_word2vec_format(\"/content/drive/MyDrive/GoogleNews-vectors-negative300.bin.gz\", binary=True)\n","# model = Doc2Vec.load(\"dtv_semeval_text8_fn\")"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"0fN6rJXuWe1v","executionInfo":{"status":"ok","timestamp":1622188410455,"user_tz":-330,"elapsed":426,"user":{"displayName":"Answer Evaluation","photoUrl":"","userId":"02627252920565144362"}}},"source":["contraction = {\n","    \"ain't\": \"is not\",\n","    \"aren't\": \"are not\",\n","    \"can't\": \"cannot\",\n","    \"can't've\": \"cannot have\",\n","    \"'cause\": \"because\",\n","    \"could've\": \"could have\",\n","    \"couldn't\": \"could not\",\n","    \"couldn't've\": \"could not have\",\n","    \"didn't\": \"did not\",\n","    \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\",\n","    \"hadn't've\": \"had not have\",\n","    \"hasn't\": \"has not\",\n","    \"haven't\": \"have not\",\n","    \"he'd\": \"he would\", \"he'd've\": \"he would have\", \"he'll\": \"he will\",\n","    \"he'll've\": \"he he will have\", \"he's\": \"he is\", \"how'd\": \"how did\",\n","    \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n","    \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\",\n","    \"I'll've\": \"I will have\", \"I'm\": \"I am\", \"I've\": \"I have\",\n","    \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",\n","    \"i'll've\": \"i will have\", \"i'm\": \"i am\", \"i've\": \"i have\",\n","    \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\",\n","    \"it'll\": \"it will\", \"it'll've\": \"it will have\", \"it's\": \"it is\",\n","    \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\",\n","    \"might've\": \"might have\", \"mightn't\": \"might not\", \"mightn't've\": \"might not have\",\n","    \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\",\n","    \"needn't\": \"need not\", \"needn't've\": \"need not have\", \"o'clock\": \"of the clock\",\n","    \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\",\n","    \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\",\n","    \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\",\n","    \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\",\n","    \"shouldn't've\": \"should not have\", \"so've\": \"so have\", \"so's\": \"so as\",\n","    \"this's\": \"this is\",\n","    \"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\",\n","    \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\",\n","    \"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\",\n","    \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\",\n","    \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\",\n","    \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\",\n","    \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\",\n","    \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n","    \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\",\n","    \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n","    \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\",\n","    \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\",\n","    \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\",\n","    \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\",\n","    \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n","    \"y'all'd've\": \"you all would have\", \"y'all're\": \"you all are\", \"y'all've\": \"you all have\",\n","    \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\",\n","    \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\"}\n","\n","\n","def clean(text):\n","    text = text.lower()\n","    temp = \"\"\n","    for i in text.split():\n","        try:\n","            temp += contraction[i]+' '\n","        except:\n","            temp += i+' '\n","    text = temp.strip()\n","    text = text.lower().translate(remove_punctuation_map)\n","    text = re.sub(\"[^a-zA-Z#]\", \" \", text)\n","    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n","    text = re.sub(r\"what's\", \"what is\", text)\n","    text = re.sub(r\",\", \"\", text)\n","    text = re.sub(r\"\\.\", \"\", text)\n","    text = re.sub(r\"!\", \"!\", text)\n","    text = re.sub(r\"\\/\", \"\", text)\n","    text = re.sub(r\"'\", \"\", text)\n","    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n","    text = re.sub(r\":\", \":\", text)\n","    text = re.sub(r' +', ' ', text)\n","    return text.strip()\n","\n","\n","def stopwordremoval(text):\n","    text = word_tokenize(text)\n","    text = [i for i in text if i not in stopw]\n","    return \" \".join(text)"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9aSmP7YFWe11"},"source":["### Question :\n","What is machine learning?\n","### Expected Answer : \n","Machine learning is the scientific study of algorithms and statistical models that computer systems use to perform a specific task without using explicit instructions, relying on patterns and inference instead. It is seen as a subset of artificial intelligence. Machine learning algorithms build a mathematical model based on sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to perform the task. Machine learning algorithms are used in a wide variety of applications, such as email filtering and computer vision, where it is difficult or infeasible to develop a conventional algorithm for effectively performing the task.\n","### Alternate Student Answer :\n","Machine Learning is the use of mathematical models to enable machines to perform tasks without instructions."]},{"cell_type":"markdown","metadata":{"id":"9rjUJWY6We15"},"source":["### Question :\n","What is mitochondrion?\n","### Expected Answer : \n","The mitochondrion is an organelle found in large numbers in most cells, in which the biochemical processes of respiration and energy production occur. It has a double membrane, the inner part being folded inwards to form cristae.\n","### Alternate Student Answer :\n","Mitochondria is the power house of the cell."]},{"cell_type":"code","metadata":{"id":"SWFNuZg8We17","executionInfo":{"status":"ok","timestamp":1622188605872,"user_tz":-330,"elapsed":646,"user":{"displayName":"Answer Evaluation","photoUrl":"","userId":"02627252920565144362"}}},"source":["#with open(\"ans_ml.txt\", \"r\") as f:\n"," #   test_ans_ml = f.read().strip()\n","#with open(\"ans_mit.txt\", \"r\") as f:\n"," #   test_ans_mit = f.read().strip()\n","key_ml = '''Machine learning (ML) is the scientific study of algorithms and statistical models that computer systems use to perform a specific task without using explicit instructions, relying on patterns and inference instead. It is seen as a subset of artificial intelligence. Machine learning algorithms build a mathematical model based on sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to perform the task. Machine learning algorithms are used in a wide variety of applications, such as email filtering and computer vision, where it is difficult or infeasible to develop a conventional algorithm for effectively performing the task.'''\n","key_mit = '''The mitochondrion is an organelle found in large numbers in most cells, in which the biochemical processes of respiration and energy production occur. It has a double membrane, the inner part being folded inwards to form cristae.'''\n","\n","test_ans_ml = '''Machine learning (ML) is the scientific study of algorithms and statistical models that computer systems use to perform a specific task without using explicit instructions, relying on patterns and inference instead. It is seen as a subset of artificial intelligence. Machine learning algorithms build a mathematical model based on sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to perform the task. Machine learning algorithms are used in a wide variety of applications, such as email filtering and computer vision, where it is difficult or infeasible to develop a conventional algorithm for effectively performing the task.'''\n","test_ans_mit = '''Mitochondria is the power house of the cell.'''"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"1xDhVA1UWe18","colab":{"base_uri":"https://localhost:8080/","height":140},"executionInfo":{"status":"ok","timestamp":1622188626985,"user_tz":-330,"elapsed":574,"user":{"displayName":"Answer Evaluation","photoUrl":"","userId":"02627252920565144362"}},"outputId":"6762439b-8310-4bbb-b941-67df4d94c0d8"},"source":["test_ans_ml"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Machine learning (ML) is the scientific study of algorithms and statistical models that computer systems use to perform a specific task without using explicit instructions, relying on patterns and inference instead. It is seen as a subset of artificial intelligence. Machine learning algorithms build a mathematical model based on sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to perform the task. Machine learning algorithms are used in a wide variety of applications, such as email filtering and computer vision, where it is difficult or infeasible to develop a conventional algorithm for effectively performing the task.'"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"-ingVA6RWe2B","colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"status":"ok","timestamp":1622188645554,"user_tz":-330,"elapsed":670,"user":{"displayName":"Answer Evaluation","photoUrl":"","userId":"02627252920565144362"}},"outputId":"9bcb399d-8679-4fe3-8b47-7e2e9a0a407f"},"source":["'''trtxt = [word_tokenize(i.lower().translate(remove_punctuation_map))\n","         for i in sent_tokenize(key_ml)+sent_tokenize(key_mit)]\n","doc = [TaggedDocument(doc, [i]) for i, doc in enumerate(trtxt)]\n","model.train(doc, total_examples=len(doc), epochs=model.epochs)'''"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'trtxt = [word_tokenize(i.lower().translate(remove_punctuation_map))\\n         for i in sent_tokenize(key_ml)+sent_tokenize(key_mit)]\\ndoc = [TaggedDocument(doc, [i]) for i, doc in enumerate(trtxt)]\\nmodel.train(doc, total_examples=len(doc), epochs=model.epochs)'"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"uOBDU5ejWe2C"},"source":["# Tokenizing Answer"]},{"cell_type":"code","metadata":{"id":"umM9xopDWe2D","executionInfo":{"status":"ok","timestamp":1622188860670,"user_tz":-330,"elapsed":884,"user":{"displayName":"Answer Evaluation","photoUrl":"","userId":"02627252920565144362"}}},"source":["def pp_set(text, op):\n","    key_tokenized_sentences = sent_tokenize(text)\n","    key_tokenized_words = word_tokenize(text)\n","    if op == \"token_sent\":\n","        return key_tokenized_sentences\n","    elif op == \"token_word\":\n","        return key_tokenized_words\n","    elif op == \"clean_sent\":\n","        return [clean(i) for i in key_tokenized_sentences]\n","    elif op == \"clean_word\":\n","        return [clean(i) for i in key_tokenized_words]\n","    elif op == \"lem_sent\":\n","        key_clean_sentences = pp_set(text, \"clean_sent\")\n","        return [\" \".join([lemmatizer.lemmatize(j) for j in i.split()]) for i in key_clean_sentences]\n","    elif op == \"lem_word\":\n","        key_clean_words = pp_set(text, \"clean_word\")\n","        return [lemmatizer.lemmatize(i) for i in key_clean_words]\n","    elif op == \"prep_sent\":\n","        key_clean_sentences = pp_set(text, \"clean_sent\")\n","        return [\" \".join([i for i in j.split() if i not in stopw]) for j in key_clean_sentences]\n","    elif op == \"prep_word\":\n","        key_preprocessed_sentences = pp_set(text, \"prep_sent\")\n","        key_preprocessed_words = []\n","        for i in key_preprocessed_sentences:\n","            key_preprocessed_words.extend(word_tokenize(i))\n","        return key_preprocessed_words\n","    elif op == \"pp_lem_word\":\n","        return [lemmatizer.lemmatize(i) for i in pp_set(text, \"prep_word\")]"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sEefZjdoWe2F"},"source":["# Semantic Similarity"]},{"cell_type":"code","metadata":{"id":"oiV8KZL0We2H","executionInfo":{"status":"ok","timestamp":1622188935606,"user_tz":-330,"elapsed":452,"user":{"displayName":"Answer Evaluation","photoUrl":"","userId":"02627252920565144362"}}},"source":["def avg_sentence_vector(words, model, num_features, index2word_set):\n","    featureVec = np.zeros((num_features,), dtype=\"float32\")\n","    nwords = 0\n","\n","    for word in words:\n","        if word in index2word_set:\n","            nwords = nwords+1\n","            featureVec = np.add(featureVec, model[word])\n","\n","    if nwords > 0:\n","        featureVec = np.divide(featureVec, nwords)\n","    return featureVec.reshape(1, -1)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"6ijGXhsrWe2I","executionInfo":{"status":"ok","timestamp":1622188942519,"user_tz":-330,"elapsed":656,"user":{"displayName":"Answer Evaluation","photoUrl":"","userId":"02627252920565144362"}}},"source":["def semantic_sim(key1, key2):\n","    print(\"key1:\", key1)\n","    print(\"key2:\", key2)\n","    try:\n","        sim = model.wv.n_similarity(key1, key2)\n","    except:\n","        vec1 = avg_sentence_vector(\n","            pp_set(key1, \"pp_lem_word\"), model1, 300, model.index2word)\n","        vec2 = avg_sentence_vector(\n","            pp_set(key2, \"pp_lem_word\"), model1, 300, model.index2word)\n","        sim = cosine_similarity(vec1, vec2)[0][0]\n","    finally:\n","        return sim"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6ywmq9yXWe2J"},"source":["# Extracting Keywords"]},{"cell_type":"code","metadata":{"id":"bLInIuCPWe2K","executionInfo":{"status":"ok","timestamp":1622188954677,"user_tz":-330,"elapsed":638,"user":{"displayName":"Answer Evaluation","photoUrl":"","userId":"02627252920565144362"}}},"source":["def extract_keywords(text):\n","    # Effectiveness : tokenized > lemmatized > clean\n","    r.extract_keywords_from_sentences(pp_set(text, \"lem_sent\"))\n","    rake_keywords = r.get_ranked_phrases()\n","    spdoc = sp(text)\n","    ner_keywords = []\n","    for ent in spdoc.ents:\n","        ner_keywords.append(ent.text)\n","    spdoc = sp(\" \".join(pp_set(text, \"clean_word\")))\n","    pytr_keywords = []\n","    for p in spdoc._.phrases:\n","        for term in p.chunks:\n","            if term.text not in pytr_keywords and term.text not in stopw:\n","                x = term.text\n","                pytr_keywords.append(x)\n","\n","    all_keywords = rake_keywords+pytr_keywords+ner_keywords\n","    all_keywords = list(set(all_keywords))\n","    sorted_keywords = list(all_keywords)\n","    sorted_keywords.sort()\n","    for i in range(len(sorted_keywords)):\n","        sorted_keywords[i] = re.sub(r' +', ' ', sorted_keywords[i])\n","\n","    return sorted_keywords"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hvxlYLphWe2M"},"source":["# Grouping Keywords"]},{"cell_type":"code","metadata":{"id":"ffpCB9XKWe2M","executionInfo":{"status":"ok","timestamp":1622189048431,"user_tz":-330,"elapsed":727,"user":{"displayName":"Answer Evaluation","photoUrl":"","userId":"02627252920565144362"}}},"source":["def group(sorted_keywords):\n","    grouped_keys = []\n","    for i in sorted_keywords:\n","        if len(grouped_keys) == 0:\n","            grouped_keys.append([i])\n","            continue\n","        else:\n","            flag = False\n","            for j in grouped_keys:\n","                if i in j:\n","                    flag = True\n","                    break\n","                temp1 = \" \".join([lemmatizer.lemmatize(t)\n","                                  for t in stopwordremoval(i).split()])\n","                for k in j:\n","                    temp2 = \" \".join([lemmatizer.lemmatize(t)\n","                                      for t in stopwordremoval(k).split()])\n","                    short = min(temp1, temp2)\n","                    long = max(temp1, temp2)\n","                    if short in long:\n","                        flag = True\n","                        j.append(i)\n","                        break\n","                if flag == True:\n","                    break\n","            if flag == False:\n","                grouped_keys.append([i])\n","    temp = []\n","    for i in grouped_keys:\n","        k = sorted(i, key=len)\n","        temp.append(k)\n","    return temp"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OJu2JzvLECGD","executionInfo":{"status":"ok","timestamp":1622189059641,"user_tz":-330,"elapsed":2214,"user":{"displayName":"Answer Evaluation","photoUrl":"","userId":"02627252920565144362"}},"outputId":"1d9d52fc-4074-4087-ff21-7001c649074d"},"source":["import nltk\n","nltk.download('wordnet')"],"execution_count":17,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"hs0lhRkeWe2N","executionInfo":{"status":"ok","timestamp":1622189066075,"user_tz":-330,"elapsed":2607,"user":{"displayName":"Answer Evaluation","photoUrl":"","userId":"02627252920565144362"}}},"source":["grouped_keys = group(extract_keywords(key_ml))\n","# grouped_keys"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ax3jbEYUWe2O"},"source":["# Removing Duplicates - longer match"]},{"cell_type":"code","metadata":{"id":"umBdTKwNWe2Q","executionInfo":{"status":"ok","timestamp":1622189070608,"user_tz":-330,"elapsed":420,"user":{"displayName":"Answer Evaluation","photoUrl":"","userId":"02627252920565144362"}}},"source":["def remove_duplicates(grouped_keys):\n","    for i in range(len(grouped_keys)):\n","        grouped_keys[i] = list(set(grouped_keys[i]))\n","        temp = list(grouped_keys[i])\n","        process_set = [\" \".join([lemmatizer.lemmatize(\n","            l) for l in stopwordremoval(j).split()]) for j in grouped_keys[i]]\n","        process_set = list(set(process_set))\n","        for temp_key1 in grouped_keys[i]:\n","            x = \" \".join([lemmatizer.lemmatize(k)\n","                          for k in stopwordremoval(temp_key1).split()])\n","            if process_set.count(x) > 1:\n","                temp.remove(temp_key1)\n","        grouped_keys[i] = temp\n","        grouped_keys[i] = sorted(grouped_keys[i])\n","\n","    for i in range(len(grouped_keys)):\n","        temp = list(grouped_keys[i])\n","        for j in range(len(grouped_keys[i])):\n","            word = grouped_keys[i][j]\n","            for k in temp:\n","                if word in k and word != k:\n","                    temp.remove(word)\n","                    break\n","        grouped_keys[i] = sorted(temp, key=len, reverse=True)\n","    grouped_keys = [i for i in grouped_keys if len(i) > 0]\n","    return grouped_keys"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"qrqfEc5pWe2R","executionInfo":{"status":"ok","timestamp":1622189078822,"user_tz":-330,"elapsed":425,"user":{"displayName":"Answer Evaluation","photoUrl":"","userId":"02627252920565144362"}}},"source":["grouped_keys = remove_duplicates(grouped_keys)\n","# grouped_keys"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kQgHMTf9We2R"},"source":["# Flatten Keywords"]},{"cell_type":"code","metadata":{"id":"gLnodnnOWe2S","executionInfo":{"status":"ok","timestamp":1622189097816,"user_tz":-330,"elapsed":433,"user":{"displayName":"Answer Evaluation","photoUrl":"","userId":"02627252920565144362"}}},"source":["def finalize(grouped_keys):\n","    temp_keywords = []\n","    final_keywords = []\n","    for i in grouped_keys:\n","        for j in i:\n","            temp_keywords.append(j)\n","\n","    temp_keywords = remove_duplicates(group(temp_keywords))\n","\n","    for i in temp_keywords:\n","        for j in i:\n","            final_keywords.append(j)\n","    return final_keywords"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"GNMHYbUXWe2T","executionInfo":{"status":"ok","timestamp":1622189100999,"user_tz":-330,"elapsed":669,"user":{"displayName":"Answer Evaluation","photoUrl":"","userId":"02627252920565144362"}}},"source":["final_keywords = finalize(grouped_keys)"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"gbx_EqC5We2U"},"source":["# final_keywords"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V8_o8W-eWe2V"},"source":["# Constructing Dictionary Key"]},{"cell_type":"code","metadata":{"id":"VTH4xem-We2V","executionInfo":{"status":"ok","timestamp":1622189120986,"user_tz":-330,"elapsed":463,"user":{"displayName":"Answer Evaluation","photoUrl":"","userId":"02627252920565144362"}}},"source":["def dictionarize(final_keywords, text):\n","    answer_key = dict()\n","    sentences = pp_set(text, \"token_sent\")\n","    for i in sentences:\n","        answer_key[i] = list()\n","    temp = list(final_keywords)\n","    for i in range(len(temp)):\n","        key = \" \".join(pp_set(temp[i], \"token_word\"))\n","        for j in answer_key:\n","            x = j.strip().lower()\n","            if key in x:\n","                answer_key[j].append(key)\n","                final_keywords.remove(temp[i])\n","                break\n","    return answer_key"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"9ggNFDYsWe2W","executionInfo":{"status":"ok","timestamp":1622189154873,"user_tz":-330,"elapsed":533,"user":{"displayName":"Answer Evaluation","photoUrl":"","userId":"02627252920565144362"}}},"source":["answer_key = dictionarize(final_keywords, key_ml)\n","# answer_key"],"execution_count":24,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rNvOggU-We2Y"},"source":["# Vectorizer"]},{"cell_type":"code","metadata":{"id":"Cd77aUjkWe2Y","executionInfo":{"status":"ok","timestamp":1622189161717,"user_tz":-330,"elapsed":650,"user":{"displayName":"Answer Evaluation","photoUrl":"","userId":"02627252920565144362"}}},"source":["def vectorize_text(answer_key):\n","    vector_keys = []\n","    vector_sent = []\n","    for i in list(answer_key.keys()):\n","        vector_sent.append(avg_sentence_vector(\n","            pp_set(i, \"token_word\"), model1, 300, model1.index2word))\n","        temp = []\n","        for j in list(answer_key[i]):\n","            temp.append(avg_sentence_vector(\n","                pp_set(j, \"token_word\"), model1, 300, model1.index2word))\n","        vector_keys.append(temp)\n","\n","    return vector_sent, vector_keys"],"execution_count":25,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"erKy_QiCWe2Z"},"source":["# Test Answer"]},{"cell_type":"code","metadata":{"id":"-z2EctDQWe2a","executionInfo":{"status":"ok","timestamp":1622189168431,"user_tz":-330,"elapsed":650,"user":{"displayName":"Answer Evaluation","photoUrl":"","userId":"02627252920565144362"}}},"source":["kw = extract_keywords(test_ans_ml)\n","final_kw = finalize(remove_duplicates(group(kw)))\n","answer_test = dictionarize(final_kw, test_ans_ml)"],"execution_count":26,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WwoNd7SXWe2a"},"source":["# Answer dictionaries"]},{"cell_type":"code","metadata":{"id":"1vzZLrJTWe2c","executionInfo":{"status":"ok","timestamp":1622189173871,"user_tz":-330,"elapsed":635,"user":{"displayName":"Answer Evaluation","photoUrl":"","userId":"02627252920565144362"}}},"source":["group_final = remove_duplicates(group(final_keywords))\n","new_final = []\n","for i in group_final:\n","    if len(i) > 1:\n","        for j in i:\n","            for k in i:\n","                if j != k and j in k:\n","                    new_final.append(j)\n","    else:\n","        new_final.append(i[-1])\n","# new_final"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"5I9IYkgMWe2d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622189179649,"user_tz":-330,"elapsed":967,"user":{"displayName":"Answer Evaluation","photoUrl":"","userId":"02627252920565144362"}},"outputId":"180e579b-fec9-4614-f000-002556c2ae39"},"source":["marks = 0\n","for i in answer_key:\n","    marks += len(answer_key[i])\n","print(marks)"],"execution_count":28,"outputs":[{"output_type":"stream","text":["28\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8bqH406TWe2e","executionInfo":{"status":"ok","timestamp":1622189194855,"user_tz":-330,"elapsed":434,"user":{"displayName":"Answer Evaluation","photoUrl":"","userId":"02627252920565144362"}}},"source":["def score(key, test):\n","    vec_key_sent, vec_key_keys = vectorize_text(key)\n","    vec_test_sent, vec_test_keys = vectorize_text(test)\n","    sum = 0\n","    sims = dict()\n","    for i in range(len(vec_test_sent)):\n","        sims[i] = []\n","        for j in range(len(vec_key_sent)):\n","            sim = cosine_similarity(vec_test_sent[i].reshape(\n","                1, -1), vec_key_sent[j].reshape(1, -1))\n","            if sim > 0.7:\n","                sims[i].append(j)\n","\n","    count = 0\n","    for keyidx in sims:\n","        ans_kw = vec_test_keys[keyidx]\n","        key_kw = []\n","        checked = []\n","        for i in sims[keyidx]:\n","            key_kw.extend(vec_key_keys[i])\n","\n","        for akw in ans_kw:\n","            max_sim = -1\n","            max_kkw = []\n","            for kkw in key_kw:\n","                if kkw in checked:\n","                    continue\n","                sim = cosine_similarity(kkw, akw)[0][0]\n","                if sim > max_sim:\n","                    max_sim = sim\n","                    max_akw = kkw\n","            if sim > 0.9:\n","                sum += 1\n","#                 count += 1\n","            else:\n","                sum += max_sim\n","#                 print(max_sim)\n","#                 count += 1\n","            checked.append(max_kkw)\n","    return sum, count"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"C-oNx328We2g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622189210362,"user_tz":-330,"elapsed":7383,"user":{"displayName":"Answer Evaluation","photoUrl":"","userId":"02627252920565144362"}},"outputId":"4a4f2601-32f5-4fae-b5a8-696bf4ed5b80"},"source":["test_score, kw_match = score(answer_key, answer_test)\n","print(test_score)\n","test_score = test_score/marks*4.0\n","# print(kw_match)\n","if (test_score % 1) > 0.5:\n","    rem = 1\n","else:\n","    rem = 0\n","final_score = int(test_score)+rem\n","print(final_score, \"/\", 4, sep='')"],"execution_count":30,"outputs":[{"output_type":"stream","text":["28.000002801418304\n","4/4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ih7i4iETWe2h","colab":{"base_uri":"https://localhost:8080/","height":140},"executionInfo":{"status":"ok","timestamp":1622189225590,"user_tz":-330,"elapsed":530,"user":{"displayName":"Answer Evaluation","photoUrl":"","userId":"02627252920565144362"}},"outputId":"29f7988d-b621-48d7-c0d8-50a4a7761ee2"},"source":["test_ans_ml"],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Machine learning (ML) is the scientific study of algorithms and statistical models that computer systems use to perform a specific task without using explicit instructions, relying on patterns and inference instead. It is seen as a subset of artificial intelligence. Machine learning algorithms build a mathematical model based on sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to perform the task. Machine learning algorithms are used in a wide variety of applications, such as email filtering and computer vision, where it is difficult or infeasible to develop a conventional algorithm for effectively performing the task.'"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"5m5tL1C8We2i","colab":{"base_uri":"https://localhost:8080/","height":140},"executionInfo":{"status":"ok","timestamp":1622189239140,"user_tz":-330,"elapsed":628,"user":{"displayName":"Answer Evaluation","photoUrl":"","userId":"02627252920565144362"}},"outputId":"b5ede3b6-8c71-4a90-8217-727386ce57e2"},"source":["key_ml"],"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Machine learning (ML) is the scientific study of algorithms and statistical models that computer systems use to perform a specific task without using explicit instructions, relying on patterns and inference instead. It is seen as a subset of artificial intelligence. Machine learning algorithms build a mathematical model based on sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to perform the task. Machine learning algorithms are used in a wide variety of applications, such as email filtering and computer vision, where it is difficult or infeasible to develop a conventional algorithm for effectively performing the task.'"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"w1hohwRcWe2k"},"source":[""],"execution_count":null,"outputs":[]}]}